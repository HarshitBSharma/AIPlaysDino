{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Learns to play Dino game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "# Bread and butter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Selenium to control the browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# To use our keyboard\n",
    "import pyautogui\n",
    "\n",
    "# To help me become Doctor Strange\n",
    "import time\n",
    "\n",
    "# Because I can't do Image processing myself\n",
    "import cv2 \n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Deque for storing experiences\n",
    "from collections import deque\n",
    "\n",
    "# Just a random import\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pur environment class which is used to play the game\n",
    "class Environment():\n",
    "\n",
    "    def __init__(self, device=\"cpu\", chrome_path=\".//Driver/chromedriver.exe\"):\n",
    "        self.done = False\n",
    "        self.device = device\n",
    "        self.initialize_chrome(chrome_path)\n",
    "        \n",
    "    def initialize_chrome(self, chrome_path):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"start-maximized\")\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self.driver = webdriver.Chrome(chrome_path, chrome_options=chrome_options)\n",
    "        \n",
    "    def reset(self, game_url=\"chrome://dino\"):\n",
    "        try:\n",
    "            self.driver.get(game_url)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def start(self):\n",
    "        pyautogui.press(\"up\")\n",
    "\n",
    "    # Hard stop\n",
    "    def close_all(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        try:\n",
    "            os.system(\"cmd /c taskkill /F /IM chromedriver.exe\")\n",
    "        except:\n",
    "            print(\"No tasks found!\")\n",
    "    \n",
    "\n",
    "    def get_screenshot(self, screenshot_path=\".//Screenshots/\"):\n",
    "        current_state = []\n",
    "        for i in range(1, 5):\n",
    "            file_name = screenshot_path + str(i) + '.jpg'\n",
    "            screenshot = pyautogui.screenshot(region=(0, 400, 1920, 330))\n",
    "            screenshot.save(file_name)\n",
    "            image_tensor = self.process_image(file_name)\n",
    "            current_state.append(image_tensor)\n",
    "        current_state = torch.cat(current_state).unsqueeze(0).to(self.device)\n",
    "        return current_state\n",
    "\n",
    "    def process_image(self, image_file):\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image[image>255] = 255\n",
    "        image = cv2.resize(image, (256, 128))\n",
    "        image = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "        image = np.reshape(image, (1, 256, 128))\n",
    "        return self.image_to_tensor(image)\n",
    "\n",
    "    def image_to_tensor(self, image):\n",
    "        image = image.astype(np.float32)\n",
    "        image_tensor = torch.from_numpy(image)\n",
    "        image_tensor = image_tensor.to(self.device, dtype=torch.float32)\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "    def jump(self):\n",
    "        pyautogui.keyDown(\"up\")\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.keyUp(\"up\")\n",
    "\n",
    "\n",
    "    def duck(self):\n",
    "        pyautogui.keyDown(\"down\")\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.keyUp(\"down\")\n",
    "\n",
    "\n",
    "    def do_nothing(self):\n",
    "        time.sleep(0.25)\n",
    "\n",
    "\n",
    "    def take_action(self, action):\n",
    "        reward = 1\n",
    "        if action == 0:\n",
    "            self.jump()\n",
    "        elif action == 1:\n",
    "            self.duck()\n",
    "        elif action == 2:\n",
    "            self.do_nothing()\n",
    "        \n",
    "        state = self.get_screenshot()\n",
    "        score = self.get_score()\n",
    "        reward = 0.1*score / 11\n",
    "        done = False\n",
    "        \n",
    "        if self.is_crashed():\n",
    "            reward = -11/score\n",
    "            done = True\n",
    "            \n",
    "        return state, reward, done\n",
    "        \n",
    "        \n",
    "    def get_score(self):\n",
    "        score_array = self.driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = \"\".join(score_array)\n",
    "        return int(score)\n",
    "        \n",
    "        \n",
    "    def view_screenshots(self, images):\n",
    "        # images are of the shape (1, 4, 256, 128)\n",
    "        images = torch.reshape(images, shape=(4, 128, 256))\n",
    "        \n",
    "        fig, ax = plt.subplots(2, 2, figsize=(14, 14))\n",
    "        x = 0\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ax[i][j].imshow(images[x], cmap=\"gray\")\n",
    "                ax[i][j].set_title(f\"Screenshot #{x}\")\n",
    "                x += 1\n",
    "        \n",
    "                \n",
    "    def is_crashed(self):\n",
    "        return self.driver.execute_script(\"return Runner.instance_.crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DinoNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DinoNetwork, self).__init__()\n",
    "        # First COnv Layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU()\n",
    "            # nn.BatchNorm1d(512)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 3),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # We will now flatten the layers\n",
    "        # Calculated using this below line\n",
    "        x = self.flatten(start_dim=1, end_dim=-1)\n",
    "        # print(f\"After flattening, shape is {x.shape}\")\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Utlitity functions\n",
    "\n",
    "# Save a model\n",
    "def save_model(data_values):\n",
    "    \"\"\"\n",
    "    Data Values is a dictionary of the following format\n",
    "    dict = {\n",
    "        'state_dict': policy_net.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epsilon': epsilon\n",
    "    }\n",
    "    \"\"\"\n",
    "    f_path = \".//v2_models/model.pt\"\n",
    "    torch.save(state, fpath)\n",
    "    \n",
    "    \n",
    "# Initializing weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        # Kaimig Uniform initialization is used for Relu Activation. It's mostly known as 'He weight initialization'.\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "batch_size = 128\n",
    "\n",
    "# Gamma (Discount rate for future rewards)\n",
    "gamma = 0.95\n",
    "\n",
    "# Exploration rate\n",
    "epsilon_start = 1\n",
    "epsilon = 1\n",
    "\n",
    "# Decay rate for Epsilon\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# Minimum Epsilon\n",
    "epsilon_min = 0.01\n",
    "\n",
    "# Updating the Target Q Network after these many episodes\n",
    "target_update = 30\n",
    "\n",
    "# Selecting the device for the iterations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setting loss criteria\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Setting the learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# Setting memory size for replay memory\n",
    "replay_memory_size = 50_000\n",
    "\n",
    "# Initalizing deque for storing experiences\n",
    "replay_memory = deque()\n",
    "\n",
    "# Setting the Number of episodes\n",
    "num_episodes = 3500\n",
    "\n",
    "# Defining our models\n",
    "policy_net = DinoNetwork().to(device)\n",
    "policy_net.apply(init_weights)\n",
    "\n",
    "target_net = DinoNetwork().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr) \n",
    "\n",
    "#Setting number of actions\n",
    "n_actions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=85.0.4183.121)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0c9483f349c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Get experience from the environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0maction_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mreward_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7ff2cc0788c>\u001b[0m in \u001b[0;36mtake_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a7ff2cc0788c>\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return Runner.instance_.distanceMeter.digits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    634\u001b[0m         return self.execute(command, {\n\u001b[0;32m    635\u001b[0m             \u001b[1;34m'script'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             'args': converted_args})['value']\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=85.0.4183.121)\n"
     ]
    }
   ],
   "source": [
    "#Creating objects\n",
    "env = Environment(device=device)\n",
    "\n",
    "agent_loss = []\n",
    "# Training loop\n",
    "for i in range(num_episodes):\n",
    "    env.reset()\n",
    "    env.jump()\n",
    "    done = False\n",
    "    \n",
    "    # Sleep time till the first obstacle arrives\n",
    "    time.sleep(4)\n",
    "    state = env.get_screenshot()\n",
    "    while not done:\n",
    "        random_number = random.random()\n",
    "        \n",
    "        if random_number <= epsilon: # Randomly explore\n",
    "            action = random.randrange(n_actions)\n",
    "        else: # Predict the action\n",
    "            q_values = target_net(state) \n",
    "            action = torch.argmax(q_values)\n",
    "            \n",
    "        # Get experience from the environment\n",
    "        next_state, reward, done = env.take_action(action)\n",
    "        action_tensor = torch.tensor(action, dtype=torch.int64, device=device)\n",
    "        reward_tensor = torch.tensor(reward, dtype=torch.int16, device=device)\n",
    "        done_tensor = torch.tensor(done, dtype=torch.bool, device=device)\n",
    "        \n",
    "        if len(replay_memory) > replay_memory_size:\n",
    "            replay_memory.popleft()\n",
    "            \n",
    "        replay_memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        if len(replay_memory) > batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "            \n",
    "            # Output Value placeholder (batch_size*number of actions)\n",
    "            targets = torch.zeros((batch_size, 3)).to(device)\n",
    "            prediction = torch.zeros((batch_size, 3)).to(device)\n",
    "            for i in range(len(minibatch)):\n",
    "                state = minibatch[i][0]\n",
    "                action = minibatch[i][1]\n",
    "                reward = minibatch[i][2]\n",
    "                next_state = minibatch[i][3]\n",
    "                done = minibatch[i][4]\n",
    "                targets[i] = model.predict(state)\n",
    "                prediction[i] = model.predict(state)\n",
    "                \n",
    "                if done:\n",
    "                    targets[i, action] = reward\n",
    "                else:\n",
    "                    targets[i, actions] = reward + gamma*torch.max(target_net(next_state))\n",
    "                                  \n",
    "            loss = criterion(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            state = next_state\n",
    "            agent_loss.append(loss)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1e2f7a158280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of Episodes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AI Agent learning how to play'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_loss' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot( [i for i in range(len(agent_loss))], agent_loss)\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('AI Agent learning how to play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended? False\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "env.reset()\n",
    "env.start()\n",
    "time.sleep(2)\n",
    "env.jump()\n",
    "print(f\"Episode ended? {env.is_crashed()}\")\n",
    "env.jump()\n",
    "#images = env.get_screenshot()\n",
    "#print(images.shape)\n",
    "#env.view_screenshots(images)\n",
    "time.sleep(2)\n",
    "env.duck()\n",
    "time.sleep(2)\n",
    "#images = env.get_screenshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03814215228614892\n"
     ]
    }
   ],
   "source": [
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 666,   3,   4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2,3, 4])\n",
    "a[1] = 666\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "state = env.get_screenshot()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9999, 4, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2,4 ,3]\n",
    "b = a\n",
    "a[1] = 9999\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bit493ebcdfe64d44eab888e13e0887aab6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
