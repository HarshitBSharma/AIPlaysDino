{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Learns to play Dino game!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "# Bread and butter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Selenium to control the browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# To use our keyboard\n",
    "import pyautogui\n",
    "\n",
    "# To help me become Doctor Strange\n",
    "import time\n",
    "\n",
    "# Because I can't do Image processing myself\n",
    "import cv2 \n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Deque for storing experiences\n",
    "from collections import deque\n",
    "\n",
    "# Just a random import\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pur environment class which is used to play the game\n",
    "class Environment():\n",
    "\n",
    "    def __init__(self, device=\"cpu\", chrome_path=\".//Driver/chromedriver.exe\"):\n",
    "        self.done = False\n",
    "        self.device = device\n",
    "        self.initialize_chrome(chrome_path)\n",
    "        \n",
    "    def initialize_chrome(self, chrome_path):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"start-maximized\")\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self.driver = webdriver.Chrome(chrome_path, chrome_options=chrome_options)\n",
    "        \n",
    "    def reset(self, game_url=\"chrome://dino\"):\n",
    "        try:\n",
    "            self.driver.get(game_url)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def start(self):\n",
    "        pyautogui.press(\"up\")\n",
    "\n",
    "    # Hard stop\n",
    "    def close_all(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        try:\n",
    "            os.system(\"cmd /c taskkill /F /IM chromedriver.exe\")\n",
    "        except:\n",
    "            print(\"No tasks found!\")\n",
    "    \n",
    "\n",
    "    def get_screenshot(self, screenshot_path=\".//Screenshots/\"):\n",
    "        current_state = []\n",
    "        for i in range(1, 5):\n",
    "            file_name = screenshot_path + str(i) + '.jpg'\n",
    "            screenshot = pyautogui.screenshot(region=(0, 400, 1920, 330))\n",
    "            screenshot.save(file_name)\n",
    "            image_tensor = self.process_image(file_name)\n",
    "            current_state.append(image_tensor)\n",
    "        current_state = torch.cat(current_state).unsqueeze(0).to(self.device)\n",
    "        return current_state\n",
    "\n",
    "    def process_image(self, image_file):\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image[image>255] = 255\n",
    "        image = cv2.resize(image, (256, 128))\n",
    "        image = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "        image = np.reshape(image, (1, 256, 128))\n",
    "        return self.image_to_tensor(image)\n",
    "\n",
    "    def image_to_tensor(self, image):\n",
    "        image = image.astype(np.float32)\n",
    "        image_tensor = torch.from_numpy(image)\n",
    "        image_tensor = image_tensor.to(self.device, dtype=torch.float32)\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "    def jump(self):\n",
    "        pyautogui.keyDown(\"up\")\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.keyUp(\"up\")\n",
    "\n",
    "\n",
    "    def duck(self):\n",
    "        pyautogui.keyDown(\"down\")\n",
    "        time.sleep(0.25)\n",
    "        pyautogui.keyUp(\"down\")\n",
    "\n",
    "\n",
    "    def do_nothing(self):\n",
    "        time.sleep(0.25)\n",
    "\n",
    "\n",
    "    def take_action(self, action):\n",
    "        reward = 1\n",
    "        if action == 0:\n",
    "            self.jump()\n",
    "        elif action == 1:\n",
    "            self.duck()\n",
    "        elif action == 2:\n",
    "            self.do_nothing()\n",
    "        \n",
    "        state = self.get_screenshot()\n",
    "        score = self.get_score()\n",
    "        reward = 0.1*score / 11\n",
    "        done = False\n",
    "        \n",
    "        if self.is_crashed():\n",
    "            reward = -11/score\n",
    "            done = True\n",
    "            \n",
    "        return state, reward, done\n",
    "        \n",
    "        \n",
    "    def get_score(self):\n",
    "        score_array = self.driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = \"\".join(score_array)\n",
    "        return int(score)\n",
    "        \n",
    "        \n",
    "    def view_screenshots(self, images):\n",
    "        # images are of the shape (1, 4, 256, 128)\n",
    "        images = torch.reshape(images, shape=(4, 128, 256))\n",
    "        \n",
    "        fig, ax = plt.subplots(2, 2, figsize=(14, 14))\n",
    "        x = 0\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ax[i][j].imshow(images[x], cmap=\"gray\")\n",
    "                ax[i][j].set_title(f\"Screenshot #{x}\")\n",
    "                x += 1\n",
    "        \n",
    "                \n",
    "    def is_crashed(self):\n",
    "        return self.driver.execute_script(\"return Runner.instance_.crashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DinoNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DinoNetwork, self).__init__()\n",
    "        # First Conv Layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=5, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2304, 64),\n",
    "            nn.ReLU()\n",
    "            # nn.BatchNorm1d(2304)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 3),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # print(f\"Dimensions of input are {inputs.shape}\")\n",
    "        x = self.conv1(inputs)\n",
    "        # print(f\"Dimensions after 1st Conv Layer are {x.shape}\")\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # We will now flatten the layers\n",
    "        # Calculated using this below line\n",
    "        x = x.flatten(start_dim=1, end_dim=-1)\n",
    "        # print(f\"After flattening, shape is {x.shape}\")\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Utlitity functions\n",
    "\n",
    "# Save a model\n",
    "def save_model(model_values):\n",
    "    \"\"\"\n",
    "    Model Values is a dictionary of the following format\n",
    "    dict = {\n",
    "        'model_dict': policy_net.state_dict(),\n",
    "        'optimizer_dict': optimizer.state_dict(),\n",
    "        'epsilon': epsilon\n",
    "    }\n",
    "    \"\"\"\n",
    "    f_path = \".//v2_models/model.pt\"\n",
    "    torch.save(model_values, f_path)\n",
    "    \n",
    "\n",
    "def load_model(model_values_path, model, optimizer):\n",
    "    moodel_values = torch.load(model_values_path)\n",
    "    model.load_state_dict(model_values['model_dict'])\n",
    "    optimizer.load_state_dict(model_values['optimizer_dict'])\n",
    "    epsilon = model_values['epsilon']\n",
    "    return model, optimizer, epsilon\n",
    "    \n",
    "    \n",
    "# Initializing weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        # Kaimig Uniform initialization is used for Relu Activation. It's mostly known as 'He weight initialization'.\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "batch_size = 2\n",
    "\n",
    "# Gamma (Discount rate for future rewards)\n",
    "gamma = 0.95\n",
    "\n",
    "# Exploration rate\n",
    "epsilon_start = 1\n",
    "epsilon = 1\n",
    "\n",
    "# Decay rate for Epsilon\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# Minimum Epsilon\n",
    "epsilon_min = 0.01\n",
    "\n",
    "# Updating the Target Q Network after these many episodes\n",
    "target_update = 40\n",
    "\n",
    "# Selecting the device for the iterations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setting loss criteria\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Setting the learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# Setting memory size for replay memory\n",
    "replay_memory_size = 50_000\n",
    "\n",
    "# Initalizing deque for storing experiences\n",
    "replay_memory = deque()\n",
    "\n",
    "# Setting the Number of episodes\n",
    "num_episodes = 2000\n",
    "\n",
    "# Defining our models\n",
    "policy_net = DinoNetwork().to(device)\n",
    "policy_net.apply(init_weights)\n",
    "\n",
    "target_net = DinoNetwork().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr) \n",
    "\n",
    "#Setting number of actions\n",
    "n_actions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_loss = []\n",
    "def train(policy_net, target_net, optimizer, epsilon, resume_training=False, model_path=None, device='cpu'):\n",
    "    # If the parameter 'resume_training' is set to True, we have to load a pre-trained model\n",
    "    if resume_training:\n",
    "        target_net, optimizer, epsilon = load_model(model_path, target_net, optimizer)\n",
    "        policy_net.load_state_dict(target.state_dict())\n",
    "        target.eval()\n",
    "        for state in optmizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device)\n",
    "    \n",
    "    #Creating objects\n",
    "    env = Environment(device=device)\n",
    "    \n",
    "    # Training loop\n",
    "    for episode in range(num_episodes):\n",
    "        env.reset()\n",
    "        env.jump()\n",
    "        done = False\n",
    "\n",
    "        # Sleep time till the first obstacle arrives\n",
    "        time.sleep(4)\n",
    "        state = env.get_screenshot()\n",
    "        while not done:\n",
    "            random_number = random.random()\n",
    "\n",
    "            if random_number <= epsilon: # Randomly explore\n",
    "                action = random.randrange(n_actions)\n",
    "            else: # Predict the action\n",
    "                q_values = target_net(state) \n",
    "                action = torch.argmax(q_values)\n",
    "\n",
    "            # Get experience from the environment\n",
    "            next_state, reward, done = env.take_action(action)\n",
    "            action_tensor = torch.tensor(action, dtype=torch.int64, device=device)\n",
    "            reward_tensor = torch.tensor(reward, dtype=torch.int16, device=device)\n",
    "            done_tensor = torch.tensor(done, dtype=torch.bool, device=device)\n",
    "\n",
    "            if len(replay_memory) > replay_memory_size:\n",
    "                replay_memory.popleft()\n",
    "\n",
    "            replay_memory.append((state, action, reward, next_state, done))\n",
    "            \n",
    "        # Sufficient data has been gathered to train the model\n",
    "        if len(replay_memory) > batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "\n",
    "            # Output Value placeholder (batch_size*number of actions)\n",
    "            targets = torch.zeros((batch_size, 3)).to(device)\n",
    "            prediction = torch.zeros((batch_size, 3)).to(device)\n",
    "            states = torch.zeros((batch_size))\n",
    "            \n",
    "            for i in range(len(minibatch)):\n",
    "                state = minibatch[i][0]\n",
    "                action = minibatch[i][1]\n",
    "                reward = minibatch[i][2]\n",
    "                next_state = minibatch[i][3]\n",
    "                done = minibatch[i][4]\n",
    "                print(f\"The shape of state is {state.shape}\")\n",
    "                targets[i] = target_net(state)\n",
    "                prediction[i] = target_net(state)\n",
    "\n",
    "                if done:\n",
    "                    targets[i, action] = reward\n",
    "                else:\n",
    "                    print(f\"Dimensions of next state are {next_state.shape}\")\n",
    "                    targets[i, action] = reward + gamma*torch.max(target_net(next_state))\n",
    "\n",
    "            loss = criterion(prediction, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            state = next_state\n",
    "\n",
    "            # Saving our model after 150 episodes\n",
    "            if episode % 150 == 0:\n",
    "                model_values = {\n",
    "                    'state_dict': target_net.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epsilon': epsilon\n",
    "                }\n",
    "                save_model(model_values)\n",
    "\n",
    "            # Updating target_net after a pre-determined number of episodes\n",
    "            if episode % target_update == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            # Recording loss for scientific purposes\n",
    "            agent_loss.append((loss/batch_size).item())\n",
    "\n",
    "            # Decaying epsilon to promote exploitation\n",
    "            epsilon = max(epsilon*epsilon_decay, epsilon_min)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of next state are torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "The shape of state is torch.Size([1, 4, 256, 128])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n",
      "Dimensions of input are torch.Size([1, 4, 256, 128])\n",
      "Dimensions after 1st Conv Layer are torch.Size([1, 32, 84, 42])\n",
      "After flattening, shape is torch.Size([1, 2304])\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=85.0.4183.121)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-0f0c1489b670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-126-58844747afdd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(policy_net, target_net, optimizer, epsilon, resume_training, model_path, device)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# Get experience from the environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0maction_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mreward_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-a7ff2cc0788c>\u001b[0m in \u001b[0;36mtake_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screenshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-a7ff2cc0788c>\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return Runner.instance_.distanceMeter.digits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    634\u001b[0m         return self.execute(command, {\n\u001b[0;32m    635\u001b[0m             \u001b[1;34m'script'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             'args': converted_args})['value']\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mD:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=85.0.4183.121)\n"
     ]
    }
   ],
   "source": [
    "train(policy_net, target_net, optimizer, epsilon, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot( [i for i in range(len(agent_loss))], agent_loss)\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('AI Agent learning how to play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\Environments\\py3.7_envs\\AiPlaysDino\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode ended? False\n",
      "Score is 22\n",
      "Score is 33\n",
      "Score is 43\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "Score is 51\n",
      "No tasks found!\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "env.reset()\n",
    "env.start()\n",
    "time.sleep(2)\n",
    "env.jump()\n",
    "print(f\"Episode ended? {env.is_crashed()}\")\n",
    "env.jump()\n",
    "#images = env.get_screenshot()\n",
    "#print(images.shape)\n",
    "#env.view_screenshots(images)\n",
    "time.sleep(2)\n",
    "env.duck()\n",
    "time.sleep(2)\n",
    "#images = env.get_screenshot()\n",
    "env.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03814215228614892\n"
     ]
    }
   ],
   "source": [
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 666,   3,   4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2,3, 4])\n",
    "a[1] = 666\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "state = env.get_screenshot()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9999, 4, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2,4 ,3]\n",
    "b = a\n",
    "a[1] = 9999\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bit493ebcdfe64d44eab888e13e0887aab6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
